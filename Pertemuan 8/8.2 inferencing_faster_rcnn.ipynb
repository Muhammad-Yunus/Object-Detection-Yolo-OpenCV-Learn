{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Inferencing Faster R-CNN\n",
    "- Inferencing faster R-CNN OpenCV DNN\n",
    "- Inferencing faster R-CNN ONNX Runtime\n",
    "\n",
    "\n",
    "> ⚠️⚠️⚠️ <font color=\"orange\">Run this notebook in your VS Code</font> ⚠️⚠️⚠️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Downgrade OpenCV to version 4.7.x\n",
    "    - This downgrade is required due to Issue related to ONNX YoloV8 in OpenCV DNN for version >= 4.8.x\n",
    "        - https://github.com/ultralytics/ultralytics/issues/1836\n",
    "    - Open Anaconda Prompt \n",
    "    - Activate environment\n",
    "    ```\n",
    "    conda activate BelajarOpenCV\n",
    "    ```\n",
    "    - Downgrade to OpenCV 4.7.x\n",
    "    ```\n",
    "    pip install --force-reinstall opencv-python==4.7.0.72 --user\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Install necesarry package, on conda prompt, execute\n",
    "    ```\n",
    "    pip install onnx\n",
    "    pip install onnxruntime\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.1 Inferencing faster R-CNN OpenCV DNN\n",
    "> ⚠️⚠️⚠️ <font color=\"orange\">OpenCV DNN with version 4.7 - 4.10 still not supported implementation of Faster R-CNN model in ONNX format</font> ⚠️⚠️⚠️<br>\n",
    ">\n",
    "> Error OpenCV 4.7 : <font color=\"#e65643\"><i>Input node with name /rpn/anchor_generator/Gather_output_0 not found in function 'cv::dnn::Subgraph::getInputNodeId</i></font><br>\n",
    "> Error OpenCV 4.9 & 4.10 : <font color=\"#e65643\"><i>concat_layer.cpp:104: error: (-215:Assertion failed) curShape.size() == outputs[0].size() in function 'cv::dnn::ConcatLayerImpl::getMemoryShapes</i></font><br><br>\n",
    ">\n",
    "> <i>We are keeping the code commented below until the update is available</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "\n",
    "# cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_model(onnx_model_path):\n",
    "#     # Load the ONNX model\n",
    "#     net = cv2.dnn.readNetFromONNX(onnx_model_path)\n",
    "#     return net\n",
    "\n",
    "# def preprocess_image(image_path):\n",
    "#     # Load the image and resize to 224x224\n",
    "#     image = cv2.imread(image_path)\n",
    "#     image_resized = cv2.resize(image, (224, 224))\n",
    "#     blob = cv2.dnn.blobFromImage(image_resized, 1/255.0, (224, 224), swapRB=True, crop=False)\n",
    "#     return image, image_resized, blob\n",
    "\n",
    "# def run_inference(net, blob):\n",
    "#     # Set the input to the network\n",
    "#     net.setInput(blob)\n",
    "    \n",
    "#     # Forward pass through the network\n",
    "#     outputs = net.forward()  # Get all the output layers\n",
    "#     return outputs\n",
    "\n",
    "# def post_process(outputs, image_shape, threshold=0.5):\n",
    "#     boxes, labels, scores = [], [], []\n",
    "    \n",
    "#     # Assuming output format: boxes, labels, scores\n",
    "#     for output in outputs:\n",
    "#         # Iterate through each detected object\n",
    "#         for detection in output:\n",
    "#             confidence = detection[2]\n",
    "#             if confidence > threshold:\n",
    "#                 # Extract box coordinates (x_min, y_min, x_max, y_max)\n",
    "#                 box = detection[3:7] * np.array([image_shape[1], image_shape[0], image_shape[1], image_shape[0]])\n",
    "#                 boxes.append(box.astype(\"int\"))\n",
    "#                 labels.append(int(detection[1]))\n",
    "#                 scores.append(float(confidence))\n",
    "    \n",
    "#     return boxes, labels, scores\n",
    "\n",
    "# def draw_detections(image, boxes, labels, scores, class_names=None):\n",
    "#     for box, label, score in zip(boxes, labels, scores):\n",
    "#         # Draw the bounding box\n",
    "#         cv2.rectangle(image, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)\n",
    "#         label_text = f\"{class_names[label]}: {score:.2f}\" if class_names else f\"Label {label}: {score:.2f}\"\n",
    "        \n",
    "#         # Put the label text\n",
    "#         cv2.putText(image, label_text, (box[0], box[1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "    \n",
    "#     return image\n",
    "\n",
    "# # Main function to perform inference\n",
    "# def main(image_path, onnx_model_path):\n",
    "#     # Load the model\n",
    "#     net = load_model(onnx_model_path)\n",
    "    \n",
    "#     # Preprocess the image\n",
    "#     original_image, resized_image, blob = preprocess_image(image_path)\n",
    "    \n",
    "#     # Run inference\n",
    "#     outputs = run_inference(net, blob)\n",
    "    \n",
    "#     # Post-process the outputs\n",
    "#     boxes, labels, scores = post_process(outputs, original_image.shape)\n",
    "    \n",
    "#     # Define class names if available\n",
    "#     class_names = [\"background\", \"scissors\"]  # Modify according to your dataset\n",
    "\n",
    "#     # Draw the detections on the original image\n",
    "#     result_image = draw_detections(original_image.copy(), boxes, labels, scores, class_names)\n",
    "    \n",
    "#     # Display the result\n",
    "#     cv2.imshow(\"Detections\", result_image)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "# # Example usage\n",
    "# image_path = \"image2.jpg\"\n",
    "# main(image_path, MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "### 8.2.2 Inferencing Faster R-CNN ONNX Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your image\n",
    "image_path = \"image2.jpg\"\n",
    "original_image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "image = cv2.resize(image, (224, 224))\n",
    "\n",
    "# normalize image\n",
    "image_norm = (image / 255.0).astype(np.float32)\n",
    "\n",
    "# Reorder the dimensions from [H, W, C] to [C, H, W]\n",
    "image_tensor = np.transpose(image_norm, (2, 0, 1))\n",
    "\n",
    "# Apply transformations and add batch dimension\n",
    "image_tensor = np.expand_dims(image_tensor, axis=0) # Shape: [1, C, H, W]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load trained Faster R-CNN model using ONNX Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ONNX model\n",
    "MODEL_NAME = \"model/fasterrcnn_resnet50_fpn_v2_scissors.onnx\"\n",
    "onnx_model = onnx.load(MODEL_NAME)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "# Initialize inference with ONNX Runtime\n",
    "ort_session = ort.InferenceSession(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- run inference on input tensor to ONNX Faster R-CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run inference\n",
    "outputs = ort_session.run(None, {\"input\": image_tensor})\n",
    "print(\"ONNX model outputs:\", outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- show detection result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "\n",
    "utility = utils.Utils()\n",
    "\n",
    "CLASS_LABELS = [\"background\", \"scissors\"]  # Modify according to your dataset\n",
    "THRESHOLD = 0.5 # Only display boxes above the confidence threshold\n",
    "\n",
    "\n",
    "image_with_box = utility.postprocess_onnx_frcnn(\n",
    "                        outputs, # ONNX prediction result \n",
    "                        original_image.copy(), # Original image\n",
    "                        CLASS_LABELS, \n",
    "                        confThreshold = THRESHOLD, \n",
    "                        font_size=0.8, \n",
    "                        color=(255,127,0), \n",
    "                        text_color=(255,255,255), \n",
    "                        input_size=[224,224] # Input tensor size\n",
    "                        ) \n",
    "\n",
    "# show result \n",
    "cv2.imshow(\"detection result\", image_with_box)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
