{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OGZrg7JO6AQ"
   },
   "source": [
    "## 8.1 Transfer Learning Faster R-CNN\n",
    "\n",
    "⚠️⚠️⚠️ *Please open this notebook in Google Colab* by click below link ⚠️⚠️⚠️<br><br>\n",
    "<a href=\"https://colab.research.google.com/github/Muhammad-Yunus/Belajar-OpenCV-ObjectDetection/blob/main/Pertemuan%208/8.1%20transfer_learning_faster_rcnn.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a><br><br><br>\n",
    "- Click `Connect` button in top right Google Colab notebook,<br>\n",
    "<img src=\"https://github.com/Muhammad-Yunus/Belajar-OpenCV-ObjectDetection/blob/main/Pertemuan%207/resource/cl-connect-gpu.png?raw=1\" width=\"250px\">\n",
    "- If connecting process completed, it will turn to something look like this<br>\n",
    "<img src=\"https://github.com/Muhammad-Yunus/Belajar-OpenCV-ObjectDetection/blob/main/Pertemuan%207/resource/cl-connect-gpu-success.png?raw=1\" width=\"250px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yss_EVvKO6AW"
   },
   "source": [
    "- Check GPU connected into Colab environment is active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bb7xG2MkO6AX"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Install necasarry package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchmetrics\n",
    "!pip install onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8TXC4uZO6AZ"
   },
   "source": [
    "#### 8.1.1 Download Dataset From Roboflow\n",
    "- Folow instruction in [4.1 dataset_annotation_roboflow.ipynb](https://github.com/Muhammad-Yunus/Belajar-OpenCV-ObjectDetection/blob/main/Pertemuan%204/4.1%20dataset_annotation_roboflow.ipynb) to prepare `Scissors Dataset` example,\n",
    "- Open `Roboflow` > `Project` > `Versions` menu\n",
    "- Then click `Download Dataset`<br>\n",
    "<img src=\"https://github.com/Muhammad-Yunus/Belajar-OpenCV-ObjectDetection/blob/main/Pertemuan%208/resource/rb-download-dataset.png?raw=1\" width=\"850px\">\n",
    "- Choose `COCO` format and select `Show download code` then click `Continue` <br>\n",
    "<img src=\"https://github.com/Muhammad-Yunus/Belajar-OpenCV-ObjectDetection/blob/main/Pertemuan%208/resource/rb-download-format.png?raw=1\" width=\"350px\">\n",
    "- click `Copy` icon to copy roboflow download code<br>\n",
    "<img src=\"https://github.com/Muhammad-Yunus/Belajar-OpenCV-ObjectDetection/blob/main/Pertemuan%208/resource/rb-copy-download-code.png?raw=1\" width=\"350px\">\n",
    "- Then <font color=\"orange\">replace below code</font> using the copied roboflow download code above,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5DDk3_LnO6AZ"
   },
   "outputs": [],
   "source": [
    "# !pip install roboflow\n",
    "\n",
    "# from roboflow import Roboflow\n",
    "# rf = Roboflow(api_key=\"xxxxxxxxxxx\")\n",
    "# project = rf.workspace(\"xxxxxxx\").project(\"xxxxxxxxxxxx\")\n",
    "# version = project.version(1)\n",
    "# dataset = version.download(\"coco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4QsHZY5F5-v"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "\n",
    "import cv2\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EBkz9i3rGDgy"
   },
   "source": [
    "- Create Pytorch Custom Dataset Loader to load `Scissors Dataset` from Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NCVhLWumO6Aa"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "\n",
    "        # Load COCO JSON annotations\n",
    "        with open(os.path.join(root, \"_annotations.coco.json\")) as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Process images and annotations\n",
    "        self.images = {img['id']: img for img in data['images'] if img['file_name'].endswith('.jpg')}\n",
    "        self.annotations = data['annotations']\n",
    "        self.categories = {cat['id']: cat['name'] for cat in data['categories']}\n",
    "\n",
    "        # Group annotations by image ID for easy lookup\n",
    "        self.img_to_anns = {img_id: [] for img_id in self.images.keys()}\n",
    "        for ann in self.annotations:\n",
    "            self.img_to_anns[ann['image_id']].append(ann)\n",
    "\n",
    "        # Store only images that have annotations\n",
    "        self.imgs = [img_id for img_id in self.img_to_anns if self.img_to_anns[img_id]]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get image and annotations for this index\n",
    "        img_id = self.imgs[idx]\n",
    "        img_info = self.images[img_id]\n",
    "        img_path = os.path.join(self.root, img_info['file_name'])\n",
    "        image = cv2.imread(img_path)  # Load image using OpenCV\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        image = torch.from_numpy(image).to(torch.float32)  # Convert NumPy array to PyTorch tensor\n",
    "        image = image.permute(2, 0, 1)  # Change the order of dimensions from (H, W, C) to (C, H, W)\n",
    "        image = image / 255.0  # Normalize pixel values to [0, 1]\n",
    "\n",
    "        # Get bounding boxes and labels\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for ann in self.img_to_anns[img_id]:\n",
    "            bbox = ann['bbox']\n",
    "            boxes.append([bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]])  # Convert to [x_min, y_min, x_max, y_max]\n",
    "            labels.append(ann['category_id'])\n",
    "\n",
    "        # Convert boxes and labels to tensors\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        target = {\"boxes\": boxes, \"labels\": labels}\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfgpm7DZGKOZ"
   },
   "source": [
    "- Load Train & Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1cG70Qr-F2OM"
   },
   "outputs": [],
   "source": [
    "# Assume dataset and DataLoader for training and validation have been set up\n",
    "DATASET_ROOT_PATH = dataset.location\n",
    "\n",
    "dataset_train = CustomDataset(root=f\"{dataset.location}/train\")\n",
    "dataset_val = CustomDataset(root=f\"{dataset.location}/valid\")\n",
    "\n",
    "data_loader_train = DataLoader(dataset_train, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "data_loader_val = DataLoader(dataset_val, batch_size=4, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "print(f\"Train Dataset : {len(dataset_train)} data, \\t Validation Dataset : {len(dataset_val)} data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Edl6oX-xH5__"
   },
   "source": [
    "- Set Dataset Class Labels and Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a-EBmAbhH5nB"
   },
   "outputs": [],
   "source": [
    "def get_dataset_count(root) :\n",
    "  with open(os.path.join(root, \"_annotations.coco.json\")) as f:\n",
    "      data = json.load(f)\n",
    "\n",
    "  # Extract all category names into a list\n",
    "  labels = [category[\"name\"] for category in data.get(\"categories\", [])]\n",
    "  return len(labels), labels\n",
    "\n",
    "\n",
    "# Define Number of dataset class and class labels based on downloaded Roboflow Dataset\n",
    "NUM_CLASS, CLASS_LABELS = get_dataset_count(root=f\"{dataset.location}/train\")\n",
    "\n",
    "print(f\"Number of Class : {NUM_CLASS}, \\t Labels : {CLASS_LABELS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_YZO4CaG7yy"
   },
   "source": [
    "- Load Pretrained <font color=\"orange\">Faster R-CNN</font> Model with <font color=\"orange\">ResNet-50</font> Backbone from [Torchvision](https://pytorch.org/vision/main/models/generated/torchvision.models.detection.fasterrcnn_resnet50_fpn_v2.html)\n",
    "  - Modify number of detection class on pretrained <font color=\"orange\">Faster R-CNN Predictor</font> (a.k.a `FastRCNNPredictor()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WPwXwNPDO6Ac"
   },
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "model = fasterrcnn_resnet50_fpn_v2(weights='DEFAULT')\n",
    "\n",
    "# Get the number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# Replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, NUM_CLASS)\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JW2_vebnKIk4"
   },
   "source": [
    "- Run <font color=\"orange\">Training Loop</font> for Pretrained Faster R-CNN with Custom Dataset downloaded from Roboflow\n",
    "  - Calculate <font color=\"orange\">Loss</font> and <font color=\"orange\">mAP</font> on each Epoch\n",
    "  - Run training loop at least for 20 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6f2HVGv3O6Ad"
   },
   "outputs": [],
   "source": [
    "# Initialize mAP metric\n",
    "map_metric = MeanAveragePrecision(iou_thresholds=[0.5, 0.75, 0.9],  # IoU thresholds\n",
    "                                  class_metrics=True)  # Separate mAP per class\n",
    "\n",
    "\n",
    "# Define SGD Optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "\n",
    "# Define Evaluation function to compute mAP on Evaulation dataset\n",
    "def evaluate(model, validation_loader, device):\n",
    "    model.eval()  # Ensure model is in eval mode\n",
    "\n",
    "    for images, targets in validation_loader:\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "\n",
    "        # Format predictions and targets for torchmetrics\n",
    "        preds = [\n",
    "            {\n",
    "                \"boxes\": output[\"boxes\"].cpu(),\n",
    "                \"scores\": output[\"scores\"].cpu(),\n",
    "                \"labels\": output[\"labels\"].cpu(),\n",
    "            }\n",
    "            for output in outputs\n",
    "        ]\n",
    "\n",
    "        gts = [\n",
    "            {\n",
    "                \"boxes\": target[\"boxes\"].cpu(),\n",
    "                \"labels\": target[\"labels\"].cpu(),\n",
    "            }\n",
    "            for target in targets\n",
    "        ]\n",
    "\n",
    "        # Update mAP metric with predictions and ground truths\n",
    "        map_metric.update(preds, gts)\n",
    "\n",
    "    # Compute mAP at the end of the epoch\n",
    "    map_result = map_metric.compute()\n",
    "    return map_result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Training loop\n",
    "NUM_EPOCH = 20\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for images, targets in data_loader_train:\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        # Forward pass\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        total_loss += losses.item()\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation step\n",
    "    mAP = evaluate(model, data_loader_val, device)\n",
    "    print(f\"Epoch {epoch+1}, \\tLoss: {total_loss/len(data_loader_train)}, \\tmAP: {mAP['map']:.4f}, \\tmAP-50: {mAP['map_50']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EBoF8wzKson"
   },
   "source": [
    "- Export trained faster R-CNN model into <font color=\"orange\">ONNX Format</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjjlPGyCWBj4"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"fasterrcnn_resnet50_fpn_v2_scissors.onnx\"\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    torch.rand(1, 3, 224, 224).to(device),\n",
    "    MODEL_NAME,  # Output path\n",
    "    export_params=True,  # Store trained weights\n",
    "    opset_version=11,    # ONNX opset version\n",
    "    do_constant_folding=True,  # Optimize model by folding constants\n",
    "    input_names=[\"input\"],  # Name of the input layer\n",
    "    output_names=[\"boxes\", \"labels\", \"scores\"],  # Names of output layers\n",
    "    dynamic_axes={\n",
    "        \"input\": {0: \"batch_size\"},  # Variable batch size\n",
    "        \"boxes\": {0: \"num_boxes\"},   # Variable number of boxes\n",
    "        \"labels\": {0: \"num_boxes\"},\n",
    "        \"scores\": {0: \"num_boxes\"}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hh-FErfCK6-E"
   },
   "source": [
    "- Download Trained Faster R-CNN ONNX Model into disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zBRzSRGpEttC"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "files.download(MODEL_NAME)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
