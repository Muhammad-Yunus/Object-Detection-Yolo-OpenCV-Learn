{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Object Detection Inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 <font color=\"orange\">Training vs Inferencing</font> Deep Learning Model\n",
    "- **Training** memerlukan **dataset** dan akan menghasilkan **Model**.\n",
    "- **Inference** memerlukan **Model** dan **data test** yang akan menghasilkan **Prediction**.  \n",
    "<img src=\"resource/training-inferencing.jpg\" style=\"width:700px\"></img><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Intro OpenCV DNN\n",
    "\n",
    "**OpenCV DNN - Deep Neural Network** adalah library untuk **Inference** atau **Forward Pass** Model Deep Learning dari beragam framework populer. Menyediakan struktur prrogram yang sederhana dan high performance (mensupport beragam CPU,GPU dan Inference Engine).\n",
    "- Compatibility : > OpenCV 3.3\n",
    "- Wiki : https://github.com/opencv/opencv/wiki/Deep-Learning-in-OpenCV\n",
    "- The supported frameworks:\n",
    "    - Caffe\n",
    "    - TensorFlow\n",
    "    - Torch\n",
    "    - Darknet (Yolo)\n",
    "    - Models in ONNX format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load Deep Learning Model using OpenCV DNN\n",
    "    - `cv2.dnn.readNet(model, configration)` \n",
    "    - where :\n",
    "        - `model` :\n",
    "            - `*.caffemodel` (Caffe, http://caffe.berkeleyvision.org/)\n",
    "            - `*.pb` (TensorFlow, https://www.tensorflow.org/)\n",
    "            - `*.t7` | `*.net` (Torch, http://torch.ch/)\n",
    "            - `*.weights` (Darknet, https://pjreddie.com/darknet/)\n",
    "        - `configuration` :\n",
    "            - `*.prototxt` (Caffe, http://caffe.berkeleyvision.org/)\n",
    "            - `*.pbtxt` (TensorFlow, https://www.tensorflow.org/)\n",
    "            - `*.cfg` (Darknet, https://pjreddie.com/darknet/)\n",
    "    - This function automatically detects an origin framework of trained model and calls an appropriate function such \n",
    "        - `cv2.dnn.readNetFromCaffe` \n",
    "        - `cv2.dnn.readNetFromTensorflow`\n",
    "        - `cv2.dnn.readNetFromTorch` \n",
    "        - `cv2.dnn.readNetFromDarknet`\n",
    "    - OpenCV DNN config file bisa ditemukan [disini](https://github.com/opencv/opencv_extra/tree/4.x/testdata/dnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Inferencing Yolo V8 - PyTorch Model using OpenCV DNN\n",
    "- To use Pytorch Model in OpenCV DNN we need to convert the Pytorch model data type `.pt` into ONNX format.\n",
    "- We will use [Convert Pytorch Model (.pt) to ONNX.ipynb](https://colab.research.google.com/drive/1IDHaSJyIauPgI_TE9UXHLm2m2nUUaKXb) Notebook file in [Google Colab](https://colab.research.google.com/)\n",
    "- On that notebook we will download Pytorch YOLOv8 small model (`yolov8s.pt`) then converting it into ONNX format `yolov8s.onnx`\n",
    "- Don't forget to put the downloaded file (`.onnx`) into the `model/` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Downgrade OpenCV to version 4.7.x\n",
    "    - This downgrade is required due to Issue related to ONNX YoloV8 in OpenCV DNN for version >= 4.8.x\n",
    "        - https://github.com/ultralytics/ultralytics/issues/1836\n",
    "    - Open Anaconda Prompt \n",
    "    - Activate environment\n",
    "    ```\n",
    "    conda activate BelajarOpenCV\n",
    "    ```\n",
    "    - Downgrade to OpenCV 4.7.x\n",
    "    ```\n",
    "    pip install --force-reinstall opencv-python==4.7.0.72 --user\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model `yolov8s` di training dengan `COCO Dataset` yang terdiri dari `80 class names` dalam `80 class index`\n",
    "- load yolo coco class names via `.load_coco_class_names_yolo()` in `coco.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coco\n",
    "\n",
    "classNames = coco.load_coco_class_names_yolo()\n",
    "\n",
    "print(classNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load yolo model\n",
    "    - pastikan `yolov8s.onnx` sudah ada dalam folder `model/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = \"model/yolov8s.onnx\"\n",
    "net = cv2.dnn.readNetFromONNX(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load image and convert to blob with `scaleFactor=1/255.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"image1.jpg\")\n",
    "\n",
    "resize_h, resize_w = 320, 320 \n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1/255.0, (resize_w, resize_h), (0, 0, 0), swapRB=True, crop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- do a net forward (inferencing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.setInput(blob)\n",
    "output = net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Postprocessing detection result via `utils.py`\n",
    "    - Apply [NMS Box](https://learnopencv.com/tag/cv-dnn-nmsboxes/)\n",
    "    - Draw Detection Box\n",
    "    - use `.postprocess` to do postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils \n",
    "utility = utils.Utils()\n",
    "\n",
    "# do a postprocessing\n",
    "img = utility.postprocess_onnx(output, img, classNames, confThreshold = 0.5, nmsThreshold = 0.3, font_size=0.5, \n",
    "                        color=(255,127,0), text_color=(255,255,255), input_size=[resize_h, resize_w])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- show result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"detection result\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inverencing from video file for Yolo - Pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = \"model/yolov8s.onnx\"\n",
    "net = cv2.dnn.readNetFromONNX(model)\n",
    "\n",
    "# load video\n",
    "cap = cv2.VideoCapture(\"video.mp4\")\n",
    "           \n",
    "# iterate for each frame in video\n",
    "while cap.isOpened():\n",
    "    \n",
    "    # get image on each frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    h, w, c = frame.shape\n",
    "    resize_h, resize_w = 320, 320\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (resize_w, resize_h), (0, 0, 0), swapRB=True, crop=False)\n",
    "\n",
    "    # do a net forward (inferencing)\n",
    "    net.setInput(blob)\n",
    "    output = net.forward()\n",
    "\n",
    "    # do a postprocessing\n",
    "    frame = utility.postprocess_onnx(output, frame, classNames, confThreshold = 0.5, nmsThreshold = 0.3, font_size=0.5, \n",
    "                            color=(255,127,0), text_color=(255,255,255), input_size=[resize_h, resize_w])\n",
    "\n",
    "    # show result\n",
    "    cv2.imshow('Frame',frame)\n",
    "\n",
    "    # wait 25ms per frame and close using 'q' \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "          break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
