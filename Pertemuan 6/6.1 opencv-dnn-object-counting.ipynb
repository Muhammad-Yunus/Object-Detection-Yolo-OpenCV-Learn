{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. OpenCV DNN Object Counting\n",
    "- Intro to Object Counting\n",
    "- Simple Object Counting using OpenCV DNN\n",
    "- Object Counting in Region of Interest (ROI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Intro Object Counting\n",
    "\n",
    "- Object counting in specific zone or region of interest <br>\n",
    "<img src=\"resource/oc4.gif\" width=\"600px\"> <br>\n",
    "source : https://blog.roboflow.com/how-to-count-objects-in-a-zone/<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Simple Object Counting using OpenCV DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import utils \n",
    "\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- since we are suing original `yolov8m.pt` trained using `COCO dataset`, we will load `classNames` from `coco.py`\n",
    "- If you are using your own model with custom dataset, you just simply define classsNames in format,\n",
    "    ```\n",
    "    classNames = [\"scissors\", \"paper\", \"cat\"]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coco\n",
    "\n",
    "classNames = coco.load_coco_class_names_yolo()\n",
    "\n",
    "print(classNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Download Yolo V8 model\n",
    "\n",
    "- For this case we will using Yolo V8 model for object detection\n",
    "- Download and Convert Yolo V8 model using colab notebook [Convert Pytorch Model (.pt) to ONNX.ipynb](https://colab.research.google.com/drive/1IDHaSJyIauPgI_TE9UXHLm2m2nUUaKXb)\n",
    "- Put the downloaded `yolov8s.onnx` into `model/` directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Utils.py modification to support simple object counting\n",
    "\n",
    "- to draw count of object in prediction result we add extra function in `utils.py`\n",
    "    - `utility.draw_object_count(img, x0, y0, font_size=0.4, color=(0,127,255), text_color=(255,255,255), padding = 10)`\n",
    "    - where : \n",
    "        - `img` : input image\n",
    "        - `x0` and `y0` : location of counting label to draw (top-left corner box in pixel)\n",
    "        - `font_size=0.4, color=(0,127,255), text_color=(255,255,255)` : default font and color style\n",
    "        - `padding = 10` : is padding between counting label (in pixel)\n",
    "\n",
    "<br><br><img src=\"resource/preview.png\" width=\"700px\">\n",
    "\n",
    "- we are also have `utility.print_object_count()` function to print detection result into text in format\n",
    "```\n",
    "'person' : 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility = utils.Utils()\n",
    "\n",
    "# load trained Yolo V8s ONNX\n",
    "model = \"model/yolov8s.onnx\"\n",
    "net = cv2.dnn.readNetFromONNX(model)\n",
    "\n",
    "\n",
    "# load sample image & convert to blob\n",
    "img = cv2.imread(\"image1.jpg\")\n",
    "\n",
    "\n",
    "resize_h, resize_w = 320, 320 \n",
    "blob = cv2.dnn.blobFromImage(img, 1/255.0, (resize_w, resize_h), (0, 0, 0), swapRB=True, crop=False)\n",
    "\n",
    "\n",
    "# do forward pass (inferencing)\n",
    "net.setInput(blob)\n",
    "output = net.forward()\n",
    "\n",
    "# do a postprocessing\n",
    "img = utility.postprocess_onnx(output, img, classNames, confThreshold = 0.5, nmsThreshold = 0.2, font_size=0.3, \n",
    "                        color=(255,127,0), text_color=(255,255,255), input_size=[resize_h, resize_w])\n",
    "\n",
    "# do print count of object\n",
    "utility.print_object_count()\n",
    "\n",
    "# do draw count of object in image\n",
    "h, w, __ = img.shape\n",
    "x0, y0 = int(0.75*w), int(0.9*h) # define counter box in 75% width , 10% height\n",
    "img = utility.draw_object_count(img, x0, y0, font_size=0.4, color=(0,127,255), text_color=(255,255,255), padding = 10)\n",
    "\n",
    "\n",
    "# show result \n",
    "cv2.imshow(\"detection result 1\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Test using camera stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility = utils.Utils()\n",
    "\n",
    "# load trained Yolo V8 ONNX\n",
    "model = \"model/yolov8s.onnx\"\n",
    "net = cv2.dnn.readNetFromONNX(model)\n",
    "\n",
    "# load video\n",
    "cap = cv2.VideoCapture(0)\n",
    "           \n",
    "# iterate for each frame in video\n",
    "while cap.isOpened():\n",
    "    \n",
    "    # get image on each frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # convert to blob\n",
    "    resize_h, resize_w = 320, 320 # use smaller image size to reduce computation \n",
    "    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (resize_w, resize_h), (0, 0, 0), swapRB=True, crop=False)\n",
    "\n",
    "    # do a net forward (inferencing)\n",
    "    net.setInput(blob)\n",
    "    output = net.forward()\n",
    "\n",
    "    # do a postprocessing\n",
    "    frame = utility.postprocess_onnx(output, frame, classNames, confThreshold = 0.6, nmsThreshold = 0.4, font_size=0.5, \n",
    "                        color=(255,127,0), text_color=(255,255,255), input_size=[resize_h, resize_w])\n",
    "\n",
    "    # do print count of object\n",
    "    utility.print_object_count()\n",
    "\n",
    "    # do draw count of object in image\n",
    "    h, w, __ = frame.shape\n",
    "    x0, y0 = int(0.75*w), int(0.1*h) # define counter box in 75% width , 10% height\n",
    "    frame = utility.draw_object_count(frame, x0, y0, font_size=0.4, color=(0,127,255), text_color=(255,255,255), padding = 10)\n",
    "\n",
    "    # show result\n",
    "    cv2.imshow('Frame',frame)\n",
    "\n",
    "    # wait 25ms per frame and close using 'q' \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "          break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Object Counting in Region of Interest (ROI)\n",
    "\n",
    "- Download sample video `mall.mp4` from https://drive.google.com/file/d/1VlwGdLnP52zs9vvRJjbOX-rWoZuSnZfv/view?usp=sharing\n",
    "- put in `Pertemuan 6/` directory (*make sure the video in same folder with this notebook*)<br><br><br>\n",
    "- We will count the object passing through the ROI like below<br>\n",
    "<img src=\"resource/oc4.gif\" width=\"500px\"> <br><br>\n",
    "- To find polygone of ROI we can use Roboflow *PolygonZone* (https://polygonzone.roboflow.com/)\n",
    "<img src=\"resource/rb-pz.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use below code to exctract specific image from video `mall.mp4`\n",
    "    - press 'q' for close the video\n",
    "    - press 's' for save the video frame into image `base_roi.jpg`, then close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load video mall.mp4\n",
    "cap = cv2.VideoCapture(\"mall.mp4\")\n",
    "           \n",
    "# iterate for each frame in video\n",
    "while cap.isOpened():\n",
    "    # get image on each frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # show result\n",
    "    cv2.imshow('Frame',frame)\n",
    "\n",
    "    # wait 1ms per frame and close using 'q' and 's' for save\n",
    "    key = cv2.waitKey(50)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    if key == ord('s'):\n",
    "        cv2.imwrite(\"base_roi.jpg\", frame)\n",
    "        print(\"`base_roi.jpg` saved successfully!\")\n",
    "        print(\"Upload the saved image into https://polygonzone.roboflow.com/ to find poligon ROI\")\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Draw polygon of ROI, then\n",
    "- copy the generated numpy array `points` on the left side\n",
    "<img src=\"resource/rb-polygonzone.gif\" width=\"700px\"><br><br>\n",
    "- paste the point as value of variable `roi_point`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility = utils.Utils()\n",
    "\n",
    "# paste the polygon point here!\n",
    "roi_point = np.array([[32, 51], [244, 46], [388, 404], [51, 408]]) # CHANGE TO YOUR OWN POLYGON\n",
    "\n",
    "origin_frame = cv2.imread(\"base_roi.jpg\")\n",
    "\n",
    "# set polygon ROI into utility instance\n",
    "h, w = origin_frame.shape[:2]\n",
    "utility.set_roi(roi_point, (h,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained Yolo V8 ONNX\n",
    "model = \"model/yolov8s.onnx\"\n",
    "net = cv2.dnn.readNetFromONNX(model)\n",
    "\n",
    "# load video\n",
    "cap = cv2.VideoCapture(\"mall.mp4\")\n",
    "           \n",
    "# iterate for each frame in video\n",
    "while cap.isOpened():\n",
    "    \n",
    "    # get image on each frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    #frame = cv2.resize(frame, (0,0), fx=0.5, fy=0.5)\n",
    "\n",
    "    # convert to blob\n",
    "    resize_h, resize_w = 320, 320 # use smaller image size to reduce computation \n",
    "    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (resize_w, resize_h), (0, 0, 0), swapRB=True, crop=False)\n",
    "\n",
    "    # do a net forward (inferencing)\n",
    "    net.setInput(blob)\n",
    "    output = net.forward()\n",
    "\n",
    "    # do a postprocessing\n",
    "    frame = utility.postprocess_onnx(output, frame, classNames, confThreshold = 0.6, nmsThreshold = 0.4, font_size=0.5, \n",
    "                        color=(255,127,0), text_color=(255,255,255), input_size=[resize_h, resize_w])\n",
    "\n",
    "    # do print count of object\n",
    "    utility.print_object_count()\n",
    "\n",
    "    # do draw count of object in image\n",
    "    h, w, __ = frame.shape\n",
    "    x0, y0 = int(0.75*w), int(0.1*h) # define counter box in 75% width , 10% height\n",
    "    frame = utility.draw_object_count(frame, x0, y0, font_size=0.4, color=(0,127,255), text_color=(255,255,255), padding = 10)\n",
    "\n",
    "    # show result\n",
    "    cv2.imshow('Frame',frame)\n",
    "\n",
    "    # wait 25ms per frame and close using 'q' \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "          break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
